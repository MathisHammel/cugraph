{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xkg10FrNThrK"
   },
   "source": [
    "# Centrality Measures with cuGraph and US Patent Citations.\n",
    "This notebook will demonstrate RAPIDS cuGraph to do centrality calculations on US Patent data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mefjUEAnZ4pq"
   },
   "source": [
    "# Downloading the data\n",
    "Commenting out and running the below lines will download and expand the data into the directory the notebook expects it to be in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lyYF0LbtFwjh"
   },
   "outputs": [],
   "source": [
    "#!wget https://s3.amazonaws.com/data.patentsview.org/download/g_patent.tsv.zip\n",
    "#!unzip ./_patent.tsv.zip\n",
    "#!wget https://s3.amazonaws.com/data.patentsview.org/download/g_us_patent_citation.tsv.zip\n",
    "#!unzip ./g_us_patent_citation.tsv.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create the dataframes using cudf and create the graphs with cuGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import cugraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method takes a list of patents and goes out one hop. It returns the new list of all the patents which can\n",
    "be used to in the same function to go out an additional hop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_hop(seeds):\n",
    "    seed_df = seeds.to_frame('seed')\n",
    "    source_df = citation_df.merge(seed_df, left_on='source', right_on='seed', how='inner')\n",
    "    target_df = (citation_df.merge(seed_df, left_on='target', right_on='seed', how='inner'))\n",
    "    links_df = cudf.concat([source_df,target_df])\n",
    "    links_df = links_df.drop('seed', axis=1)\n",
    "    new_seed_set = links_df.melt()\n",
    "    new_seed_set = new_seed_set.drop('variable',axis=1)\n",
    "    new_seed_set = new_seed_set['value'].drop_duplicates()\n",
    "    return links_df.drop_duplicates(), new_seed_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function displays the top results of all the centrality algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print function\n",
    "def print_centrality(k, dc, bc, kr, pr, ev):\n",
    "\n",
    "    dc_top = dc.sort_values(by='degree_centrality', ascending=False).head(k).to_pandas()\n",
    "    bc_top = bc.sort_values(by='betweenness_centrality', ascending=False).head(k).to_pandas()\n",
    "    kr_top = kr.sort_values(by='katz_centrality', ascending=False).head(k).to_pandas()\n",
    "    pr_top = pr.sort_values(by='pagerank', ascending=False).head(k).to_pandas()\n",
    "    ev_top = ev.sort_values(by='eigenvector_centrality', ascending=False).head(k).to_pandas()\n",
    "    \n",
    "    df1_styler = dc_top.style.set_table_attributes(\"style='display:inline'\").set_caption('Degree').hide(axis='index')\n",
    "    df2_styler = bc_top.style.set_table_attributes(\"style='display:inline'\").set_caption('Betweenness').hide(axis='index')\n",
    "    df3_styler = kr_top.style.set_table_attributes(\"style='display:inline'\").set_caption('Katz').hide(axis='index')\n",
    "    df4_styler = pr_top.style.set_table_attributes(\"style='display:inline'\").set_caption('PageRank').hide(axis='index')\n",
    "    df5_styler = ev_top.style.set_table_attributes(\"style='display:inline'\").set_caption('EigenVector').hide(axis='index')\n",
    "\n",
    "    display_html(df1_styler._repr_html_()+df2_styler._repr_html_()+df3_styler._repr_html_()+df4_styler._repr_html_()+df5_styler._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the centrality algorithms, this function displays the supplied graph. The dataframe from any of the centrality calculations is also supplied along with the number of the highest ranking nodes we want to emphasize with labels and scale with size based on the centrality value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_centrality_graph(graph_df, number_to_label, cent_df):\n",
    "    import networkx as nx\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    top_ones = cent_df.sort_values(by=cent_df.columns[0], ascending=False).head(number_to_label)[cent_df.columns[1]].to_pandas()\n",
    "    print(top_ones)\n",
    "    sizes = []\n",
    "    nodes = []\n",
    "\n",
    "    plt.rcParams['figure.figsize'] = [12, 8]\n",
    "    nx_g = nx.from_pandas_edgelist(graph_df.to_pandas())\n",
    "\n",
    "    for node in nx_g.nodes():\n",
    "        cent_value =cent_df.loc[cent_df['vertex'] == node, cent_df.columns[0]].values[0]\n",
    "        nodes.append(node)\n",
    "        sizes.append((cent_value[0]*3000+10).item())\n",
    "\n",
    "    pos = nx.spring_layout(nx_g)\n",
    "    labels = {node: node for node in top_ones}\n",
    "    nx.draw(nx_g, pos=pos, nodelist=nodes,font_color='red' ,node_size=sizes,node_color='grey', node_shape='o', linewidths=2, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function executes the five Centrality Algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Centrality\n",
    "# the centrality calls are very straightforward with the graph being the primary argument\n",
    "# we are using the default argument values for all centrality functions except where noted.\n",
    "\n",
    "def compute_centrality(_graph, highest_degree=2000) :\n",
    "\n",
    "    # Compute Degree Centrality\n",
    "    _d = cugraph.degree_centrality(_graph)\n",
    "    print(\"Degree Centrality done\")\n",
    "\n",
    "    # Compute the Betweenness Centrality\n",
    "    # The k value is needed in large graphs as by default it will calculate the for every pair in the graph.\n",
    "    # in this case we limit it to 100 samples at most.\n",
    "    _b = cugraph.betweenness_centrality(_graph,k=100)\n",
    "    print(\"Between Centrality done\")\n",
    "\n",
    "    #Compute Katz Centrality\n",
    "    # alpha is set to one divided by the maximum degree in the graph. This will enable convergence\n",
    "    # max_iter will determine how many iterations will be run before giving up if convergence doesn't occur\n",
    "    # tol is the tolerance which determines the maximum difference that indicatates convergence \n",
    "    _k = cugraph.katz_centrality(_graph, max_iter=1000, tol=1.0e-2,alpha=1/highest_degree)\n",
    "    print(\"Katz Centrality done\")\n",
    "\n",
    "    # Compute PageRank Centrality\n",
    "    _p = cugraph.pagerank(_graph)\n",
    "    print(\"Pagerank done\")\n",
    "\n",
    "    # Compute EigenVector Centrality\n",
    "    _e = cugraph.eigenvector_centrality(_graph, max_iter=1000, tol=1.0e-3)\n",
    "    print(\"Eigenvector Centrality done\")\n",
    "\n",
    "    return _d, _b, _k, _p, _e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load the entire US patent citation edge list in to a cuDF dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the citation graph\n",
    "import cudf\n",
    "citation_df = cudf.read_csv(\"../data/g_us_patent_citation.tsv\",\n",
    "                sep='\\t',\n",
    "                header=0,\n",
    "                usecols=[0,2],\n",
    "                names=[\"source\", \"target\"],\n",
    "                dtype={\"source\":str,\"target\":str},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first five edges in the dataframe.\n",
    "citation_df.iloc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting dataframe has over 142 million edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(citation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a patent of interest. In this case we will choose a patent representing an advance in visualizing machine learning models. Adding additional patents to the seed list can be done here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi = [\"10810491\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go out one hop from the patent(s) supplied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_series=cudf.Series(poi)\n",
    "first_hop_df, first_set = next_hop(seed_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(first_hop_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_hop_df, second_hop_seeds = next_hop(first_set)\n",
    "third_hop_df, third_hop_seeds = next_hop(second_hop_seeds)\n",
    "fourth_hop_df, fourth_hop_seeds = next_hop(third_hop_seeds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are node (patent) counts at each hop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(first_set), len(second_hop_seeds),len(third_hop_seeds),len(fourth_hop_seeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are edge counts at each hop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(first_hop_df), len(second_hop_df),len(third_hop_df),len(fourth_hop_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The contents of the dataframe at 2 hops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_hop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "G = cugraph.from_cudf_edgelist(second_hop_df,create_using=cugraph.Graph(directed=True),source='source', destination='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dc, bc, kc, pr, ev = compute_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "\n",
    "print_centrality(10, dc, bc, kc, pr, ev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calls the function that draws the graph with the specified number of the most central nodes labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_centrality_graph(second_hop_df,12, pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load the enrichment data. We are only loading the patent_id and title but other columns are available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_df = cudf.read_csv(\"/home/dacosta/data/g_patent.tsv\",\n",
    "                sep='\\t',\n",
    "                header=0,\n",
    "                usecols=[0,3],\n",
    "                names=[\"patent_id\", \"patent_title\"],\n",
    "                dtype={\"patent_id\":\"str\",\"patent_title\":str},\n",
    ")\n",
    "len(title_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets run edge betweenness centrality to find the central edges in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_2_hops = cugraph.from_cudf_edgelist(second_hop_df,create_using=cugraph.Graph(directed=True),source='source', destination='target')\n",
    "results=cugraph.edge_betweenness_centrality(G_2_hops).sort_values(ascending=False,by=['betweenness_centrality'])\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the enrichment data with the highest ranking patent ids found above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top number of Patents we are interested in\n",
    "k=20\n",
    "\n",
    "dc_top = dc.sort_values(by='degree_centrality', ascending=False).head(k)\n",
    "bc_top = bc.sort_values(by='betweenness_centrality', ascending=False).head(k)\n",
    "kr_top = kc.sort_values(by='katz_centrality', ascending=False).head(k)\n",
    "pr_top = pr.sort_values(by='pagerank', ascending=False).head(k)\n",
    "ev_top = ev.sort_values(by='eigenvector_centrality', ascending=False).head(k)\n",
    "\n",
    "df_list = [dc_top, bc_top, kr_top, pr_top, ev_top]\n",
    "combined = cudf.concat(df_list, axis=0)\n",
    "combined = cudf.DataFrame(combined['vertex'])\n",
    "print(combined.columns)\n",
    "combined = combined.drop_duplicates()\n",
    "enriched_df = title_df.merge(combined, left_on='patent_id', right_on='vertex', how='inner')\n",
    "enriched_df = enriched_df.drop('vertex', axis=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the results of the enriched dataframe. We do this in pandas in order to override the default max column width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "enriched_df.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k2DfAaZaDIBj"
   },
   "source": [
    "---\n",
    "U.S. Patent and Trademark Office. “Data Download Tables.” PatentsView. Accessed [10/06/2024]. https://patentsview.org/ download/data-download-tables.\n",
    "\n",
    "Data used is Licensed under Creative Commons 4.0 \n",
    "https://creativecommons.org/licenses/by/4.0/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Copyright (c) 2024, NVIDIA CORPORATION.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");  you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
